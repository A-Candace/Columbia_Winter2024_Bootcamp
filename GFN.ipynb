{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c84382-f15c-41f8-ac90-9369f7bccfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a1961d9-86bc-4011-be0d-a57280d19908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import openpyxl\n",
    "\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f798eeb9-30d9-4334-b62f-4f733c065f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_info = pd.read_excel('ClusterInformation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e154b068-c981-4305-ae35-57cf4be0c967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your graph based on latitude and longitude\n",
    "def create_graph_from_coordinates(cluster_info):\n",
    "    G = nx.Graph()\n",
    "    for idx, row in cluster_info.iterrows():\n",
    "        node_name = row['Cluster']\n",
    "        latitude = row['lat']\n",
    "        longitude = row['lng']\n",
    "        G.add_node(node_name, latitude=latitude, longitude=longitude)\n",
    "    \n",
    "    # Define edges based on geographical proximity or any other criteria\n",
    "    # For example, you can connect nodes if they are within a certain distance.\n",
    "    # Here, we connect nodes if they are within 0.1 degrees of latitude or longitude.\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        u_lat, u_lng = G.nodes[u]['latitude'], G.nodes[u]['longitude']\n",
    "        v_lat, v_lng = G.nodes[v]['latitude'], G.nodes[v]['longitude']\n",
    "        if abs(u_lat - v_lat) <= 0.005 or abs(u_lng - v_lng) <= 0.005:\n",
    "        #if abs(u_lat - v_lat) <= 0.5 or abs(u_lng - v_lng) <= 0.5:\n",
    "            G[u][v]['weight'] = 1.0  # You can assign a weight to the edges\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ade035-6c26-4a44-82e5-9d8f87d83660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load predictor and target data\n",
    "def load_data(predictor_folder, target_folder):\n",
    "    predictor_data = {}\n",
    "    target_data = {}\n",
    "    for node_name in os.listdir(predictor_folder):\n",
    "        predictor_file = os.path.join(predictor_folder, node_name)\n",
    "        if os.path.isfile(predictor_file) and predictor_file.endswith('.xlsx'):\n",
    "            node_df = pd.read_excel(predictor_file)\n",
    "            predictor_data[node_name] = node_df\n",
    "            \n",
    "    for node_name in os.listdir(target_folder):\n",
    "        target_file = os.path.join(target_folder, node_name)\n",
    "        if os.path.isfile(target_file) and target_file.endswith('.xlsx'):\n",
    "            node_df = pd.read_excel(target_file)\n",
    "            target_data[node_name] = node_df\n",
    "    \n",
    "    return predictor_data, target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4285295b-2dd5-4261-beea-9401d35186ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets based on date ranges\n",
    "def split_data(predictor_data, target_data, start_date, end_date):\n",
    "    train_predictors = {}\n",
    "    test_predictors = {}\n",
    "    train_targets = {}\n",
    "    test_targets = {}\n",
    "    \n",
    "    for node_name, predictor_df in predictor_data.items():\n",
    "        target_df = target_data.get(node_name)\n",
    "        if target_df is not None:\n",
    "            mask_train = (predictor_df['Date'] >= start_date) & (predictor_df['Date'] < end_date)\n",
    "            mask_test = (predictor_df['Date'] >= end_date)\n",
    "            \n",
    "            train_predictors[node_name] = predictor_df[mask_train]\n",
    "            test_predictors[node_name] = predictor_df[mask_test]\n",
    "            \n",
    "            train_targets[node_name] = target_df[mask_train]\n",
    "            test_targets[node_name] = target_df[mask_test]\n",
    "    \n",
    "    return train_predictors, test_predictors, train_targets, test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1c0c17-ad7b-4610-8adc-07956bbf8c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build the adjacency matrix (graph) based on coordinates\n",
    "G = create_graph_from_coordinates(cluster_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf39bb2-c42f-4791-be7b-8ae24fcbaf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and split into training and test sets\n",
    "predictor_folder = 'Predictors'\n",
    "target_folder = 'Response'\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2018-01-02'  # Adjust as needed\n",
    "\n",
    "predictor_data, target_data = load_data(predictor_folder, target_folder)\n",
    "train_predictors, test_predictors, train_targets, test_targets = split_data(\n",
    "    predictor_data, target_data, start_date, end_date\n",
    ")\n",
    "\n",
    "# Preprocess your predictor and target data as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6866832c-958c-49ec-9fb7-133a7b91392a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define and build your GNN model using TensorFlow and Keras\n",
    "def build_gnn_model(input_shape, num_output_nodes):\n",
    "    model = keras.Sequential([\n",
    "        # Define your GNN layers here\n",
    "        # Example: layers.GCNConv(32, activation='relu'),\n",
    "        # Add more layers as needed\n",
    "\n",
    "        \n",
    "        ###keras.layers.GATConv(32, activation='relu')\n",
    "\n",
    "        keras.layers.Dense(32, activation='relu'),  # Adjust parameters as needed\n",
    "        #keras.layers.Dense(64, activation='relu'),  # Add more layers as needed\n",
    "        keras.layers.Dense(32, activation='relu'), \n",
    "        #keras.layers.Dense(32, activation='relu'), \n",
    "        # Output layer\n",
    "        keras.layers.Dense(num_output_nodes)  # Adjust the number of output nodes\n",
    "\n",
    "        # Output layer\n",
    "        #keras.layers.GraphConv(32, activation='relu')\n",
    "\n",
    "        #keras.layers.Dense(num_output_nodes)  # Adjust the number of output nodes\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')  # Adjust the loss function as needed\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f936f6f-b2b7-4dd3-9f12-b762395eb8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define GNN model hyperparameters\n",
    "predictor_dim = 5  # Replace with the actual number of predictor features\n",
    "input_shape = (None, predictor_dim)  # Adjust the input shape based on your data\n",
    "num_output_nodes = 1  # Adjust for your regression task\n",
    "input_shape = (None, predictor_dim)  # Adjust the input shape based on your data\n",
    "num_output_nodes = 1  # Adjust for your regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd367732-b046-4525-a2ca-b9687133c40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build the GNN model\n",
    "gnn_model = build_gnn_model(input_shape, num_output_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ab0d02-4739-48a5-ba92-2026f3a0b706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - 1s 2ms/step - loss: 28.2538\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 13.6177\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 13.5015\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.8872\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.7657\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.1965\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.6618\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.0201\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.2029\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.5133\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.1685\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.1151\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 964us/step - loss: 12.1090\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.0325\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.6957\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 999us/step - loss: 11.5081\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.8149\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 12.3559\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 999us/step - loss: 11.3172\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 709us/step - loss: 10.9588\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 982us/step - loss: 11.2441\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.9006\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.9377\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.6842\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.5918\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.4484\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 971us/step - loss: 10.8251\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 987us/step - loss: 11.8891\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.9168\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.0255\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 981us/step - loss: 10.1696\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 635us/step - loss: 10.3077\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.5556\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.5678\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 980us/step - loss: 10.2524\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 671us/step - loss: 10.8878\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 993us/step - loss: 11.7990\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 971us/step - loss: 10.4589\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 975us/step - loss: 9.7790\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.5352\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 11.2765\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.5804\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.4787\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.7396\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 10.3076\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.7187\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 982us/step - loss: 10.2465\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.8790\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.5783\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 9.9531\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 0s 953us/step - loss: 17.4135\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 999us/step - loss: 16.1166\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.7715\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.6851\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 989us/step - loss: 15.8082\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.2071\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 981us/step - loss: 15.4049\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.0227\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.0869\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 15.0211\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 993us/step - loss: 14.8677\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 625us/step - loss: 14.9641\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 643us/step - loss: 15.7332\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.6808\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 965us/step - loss: 15.3812\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 983us/step - loss: 14.5895\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 992us/step - loss: 14.5181\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 988us/step - loss: 14.3231\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 992us/step - loss: 14.7963\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.8598\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.3702\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.8418\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 686us/step - loss: 14.7050\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.5462\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 987us/step - loss: 15.1440\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 955us/step - loss: 14.9382\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.1223\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.2976\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.0921\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.7856\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.1196\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 13.9629\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 994us/step - loss: 14.2114\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.3304\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.2083\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.4809\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 683us/step - loss: 14.4047\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.6486\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 977us/step - loss: 14.2139\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.0207\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 995us/step - loss: 13.9759\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 996us/step - loss: 13.9654\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 991us/step - loss: 13.8325\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.0313\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 998us/step - loss: 14.7827\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 13.9114\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 994us/step - loss: 13.9018\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 683us/step - loss: 13.5038\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 669us/step - loss: 14.0801\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 14.1343\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 5.1612\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.7343\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.6011\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.4678\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.3582\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.3980\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.3880\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 977us/step - loss: 3.2503\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 984us/step - loss: 3.2066\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 631us/step - loss: 3.1427\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.1986\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 984us/step - loss: 3.1638\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.1447\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 987us/step - loss: 3.1322\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.1300\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0565\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.1401\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0568\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0738\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0316\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0434\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 997us/step - loss: 2.9993\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9942\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9779\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 644us/step - loss: 3.1616\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 652us/step - loss: 3.0430\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9689\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9986\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9436\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 959us/step - loss: 2.9665\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.0504\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 994us/step - loss: 2.9691\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9186\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 998us/step - loss: 2.8872\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8903\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9290\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8752\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 3.1054\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8722\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.7923\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8163\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.9344\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8204\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8199\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8276\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8244\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 735us/step - loss: 2.8283\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.8966\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 734us/step - loss: 2.7337\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1000us/step - loss: 2.8386\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 0s 879us/step - loss: 0.3824\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3644\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3566\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3505\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3499\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 636us/step - loss: 0.3437\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 632us/step - loss: 0.3436\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3434\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 981us/step - loss: 0.3374\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 945us/step - loss: 0.3418\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 984us/step - loss: 0.3320\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 951us/step - loss: 0.3347\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 976us/step - loss: 0.3319\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 617us/step - loss: 0.3301\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3339\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3284\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 730us/step - loss: 0.3287\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3333\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3280\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3274\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3252\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3291\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3276\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3286\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3245\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3263\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3214\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3239\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3191\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3300\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3197\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3265\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3206\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3175\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3128\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3206\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3138\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3280\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3187\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3146\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3149\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3156\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3110\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3109\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3142\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3265\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3074\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3121\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3088\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3086\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 0s 917us/step - loss: 1.2603\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.1803\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0500\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 972us/step - loss: 1.1125\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0151\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0261\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0264\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0366\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0082\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0164\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9911\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0143\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9783\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9784\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9725\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9304\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9661\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9483\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9575\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9466\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9257\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 735us/step - loss: 0.9332\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9709\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 962us/step - loss: 0.9159\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 990us/step - loss: 0.9488\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 971us/step - loss: 0.9089\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9157\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9214\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9658\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9562\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9508\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8986\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9277\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8881\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8934\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9037\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8888\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8586\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.0702\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9296\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8863\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8652\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 723us/step - loss: 0.8537\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9024\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8866\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8856\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8644\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8532\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8515\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8494\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 0s 948us/step - loss: 0.8977\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8539\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8494\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8434\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8353\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8275\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8294\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8187\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8207\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8211\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8109\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8268\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8078\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8183\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 660us/step - loss: 0.8029\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 651us/step - loss: 0.8034\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8061\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.8015\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.7946\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7979\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7966\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7850\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7963\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7949\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7940\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7805\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7824\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7775\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7742\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7758\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7702\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7813\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7599\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7948\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7673\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7674\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7603\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7697\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7601\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7620\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7579\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7539\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7509\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7538\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7488\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7517\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7354\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7555\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7490\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.7546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the GNN model\n",
    "for node_name, train_predictor_df in train_predictors.items():\n",
    "    train_target_df = train_targets[node_name]\n",
    "    train_predictors_array = train_predictor_df.drop('Date', axis=1).values\n",
    "    train_targets_array = train_target_df['Flooding'].values\n",
    "    \n",
    "    # Train the model for each node\n",
    "    gnn_model.fit(train_predictors_array, train_targets_array, epochs=50)  # Adjust epochs and batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef2615f-c313-4089-9d47-765bc07c9c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 583us/step\n",
      "Node 3.xlsx - Mean Squared Error: 12.56759667438056\n",
      "23/23 [==============================] - 0s 535us/step\n",
      "Node 1.xlsx - Mean Squared Error: 29.498054092771962\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Node 4.xlsx - Mean Squared Error: 7.433908629491989\n",
      "23/23 [==============================] - 0s 573us/step\n",
      "Node 2.xlsx - Mean Squared Error: 0.7094134106116973\n",
      "23/23 [==============================] - 0s 526us/step\n",
      "Node 5.xlsx - Mean Squared Error: 2.5657786295372715\n",
      "23/23 [==============================] - 0s 525us/step\n",
      "Node 0.xlsx - Mean Squared Error: 1.0449257417495608\n",
      "23/23 [==============================] - 0s 586us/step\n",
      "23/23 [==============================] - 0s 677us/step\n",
      "Node 3.xlsx - Mean Squared Error: 12.56759667438056, R2 Score: 0.5045920693748721\n",
      "23/23 [==============================] - 0s 545us/step\n",
      "23/23 [==============================] - 0s 569us/step\n",
      "Node 1.xlsx - Mean Squared Error: 29.498054092771962, R2 Score: 0.27574972760048955\n",
      "23/23 [==============================] - 0s 1ms/step\n",
      "23/23 [==============================] - 0s 511us/step\n",
      "Node 4.xlsx - Mean Squared Error: 7.433908629491989, R2 Score: 0.4317809539529043\n",
      "23/23 [==============================] - 0s 550us/step\n",
      "23/23 [==============================] - 0s 568us/step\n",
      "Node 2.xlsx - Mean Squared Error: 0.7094134106116973, R2 Score: 0.3252544584679067\n",
      "23/23 [==============================] - 0s 541us/step\n",
      "23/23 [==============================] - 0s 542us/step\n",
      "Node 5.xlsx - Mean Squared Error: 2.5657786295372715, R2 Score: 0.3787049560807155\n",
      "23/23 [==============================] - 0s 564us/step\n",
      "23/23 [==============================] - 0s 508us/step\n",
      "Node 0.xlsx - Mean Squared Error: 1.0449257417495608, R2 Score: 0.34196111710314037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the GNN model on the test set\n",
    "for node_name, test_predictor_df in test_predictors.items():\n",
    "    test_target_df = test_targets[node_name]\n",
    "    test_predictors_array = test_predictor_df.drop('Date', axis=1).values\n",
    "    test_targets_array = test_target_df['Flooding'].values\n",
    "    \n",
    "    # Evaluate the model for each node\n",
    "    mse = mean_squared_error(test_targets_array, gnn_model.predict(test_predictors_array))\n",
    "    print(f\"Node {node_name} - Mean Squared Error: {mse}\")\n",
    "    \n",
    "for node_name, test_predictor_df in test_predictors.items():\n",
    "    test_target_df = test_targets[node_name]\n",
    "    test_predictors_array = test_predictor_df.drop('Date', axis=1).values\n",
    "    test_targets_array = test_target_df['Flooding'].values\n",
    "    \n",
    "    # Evaluate the model for each node\n",
    "    mse = mean_squared_error(test_targets_array, gnn_model.predict(test_predictors_array))\n",
    "    r2 = r2_score(test_targets_array, gnn_model.predict(test_predictors_array))  # Calculate R2 score\n",
    "    print(f\"Node {node_name} - Mean Squared Error: {mse}, R2 Score: {r2}\")\n",
    "# You can also use the trained model to make predictions for new data\n",
    "\n",
    "# Visualize results on a map (optional)\n",
    "# Use latitude and longitude information from cluster_info and predicted values\n",
    "# You can use libraries like matplotlib or folium for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935373a-9b21-4c62-87ad-417c6e470643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
